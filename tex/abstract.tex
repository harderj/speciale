
This paper is mainly about the part of reinforcement learning that is called
Q-learning, which is a category of algorithms which can \emph{learn} from
interaction with a decision process.
We present the background theory for these algorithms,
a variety of settings in which Q-learning has been analysed
and the results of such analyses.
In the course of this we discuss the relations between the various settings
and their results.
Finally we will present and prove a yet unpublished result
\mcite{F20}
which uses the fitted Q-iteration algorithm to prove
convergence rates of Q-learning in the case of a
continuous state space Markov decision process.

